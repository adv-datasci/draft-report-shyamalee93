---
title: "Project Report"
author: "Shyamalee"
date: "October 8, 2017"
output:
  pdf_document: default
  html_document: default
  word_document: default
---
__Research Question__ : Zillow has 'Zestimates', that are estimated home values based on hundreds of data points on a property. Given the features of properties in three counties in California, would you be able to further reduce the Mean Absolute Error from what Zillow has it at now? 

__Objective__ : For each unique property, one has to predict a log error for each time point at October 2016, November 2016, December 2016, October 2017, November 2017, December 2017. The evaluation is based on the Mean Log Error given by:
$logerror=log(Zestimate)-log(SalePrice)$
Our submission must have a log error at six different points in time for each unique property. 

## Project Plan
1. Start with looking at the dataset in R
2. Data files :
  + Properties.csv : Contains a list of all properties and 58 features for each properties
  + train_2016 : Contains the training dataset which has the parcelID (Unique house identifier), transaction date and mean log error between actual sale price and Zestimate
  + Submission file - Contains mean log error across six time periods for every individual parcel ID
3. Do some Exploratory Data Analysis on properties.csv 
  + Figure out the categorical and continuous variables
  + Plot the distributions of continuous variables
  + Check variables have over 75-80 percent missing values, check if they can be imputed or discard them
  + Check if more variables can be determined: Ratios etc. 
4. Imputing Missing Values - based on the specific variable
5. Applying Machine Learning Algorithms to the Data
  + Fit a simple linear model with all parameters
  + Fit lasso/ ridge/ eslasticnet regression models 
  + Random Forest
  + GBM 
  + XGBoost
  
\newpage 
## 1. Exploratory Data Analysis
From the Kaggle website, we see that there are three files available for download. One of them, properties.csv has all the features of houses in three counties in USA and we load these files to look at how few of the variables are distributed. 

```{r setup, include=FALSE}
zillow_property <- read.csv("../properties_2016.csv")
train <- read.csv("../train_2016_v2.csv")
train = merge(zillow_property, train, by="parcelid",all.y=TRUE)
```

```{r setup, include=FALSE}
#Get percentage of NA's across features
total_na = as.data.frame(sapply(train, function(x) round((sum(is.na(x))/length(x)) * 100,2)))
colnames(total_na) <- "Percent_NA"
total_na <- cbind(Features = rownames(total_na), total_na)
total_na <- total_na %>% arrange(desc(Percent_NA))
```


```{r setup, include=FALSE}
#Plot missing data by feature
total_na %>% 
    filter(Percent_NA > 0) %>% 
    ggplot(aes(x=reorder(Features, -Percent_NA), y=Percent_NA)) + 
    geom_bar(stat='identity', fill='blue') +
    labs(x='', y='% missing', title='Percent missing data by feature') +
    theme(axis.text.x=element_text(angle=90, hjust=1)) + coord_flip() + theme_bw()
```

```{r setup, include=FALSE}
## Distribution of what you have to predict - the logerror
train %>%
    ggplot(aes(x=logerror)) + 
    geom_density(fill='steelblue', color='steelblue') + 
    ggtitle('Distribution of logerror') + theme_bw()
```


```{r setup, include=FALSE}
## Distribution of error over the time

# Change transaction date to date object from integer
train$transactiondate = as.Date(train$transactiondate)

train %>%
    group_by(transactiondate) %>% 
    summarise(mean_abs_logerror = mean(abs(logerror))) %>%
    ggplot(aes(x=transactiondate, y = mean_abs_logerror)) + 
    geom_bar(stat='identity', fill='steelblue') + 
    labs(x='', y='Mean log error', title='Absolute mean log error over time') + theme_bw()
```


```{r setup, include=FALSE}
## Count transactions by day
train %>% 
  group_by(transactiondate) %>% 
  tally() %>% 
  ggplot(aes(x=transactiondate, y=n)) + 
    geom_bar(stat='identity', color='steelblue') + 
    labs(x='', y='Number of transactions', title='Total transactions by day') + theme(bw)
```


```{r setup, include=FALSE}
## Use Leaflet to plot where the houses are
train %>%
     leaflet() %>%
     addTiles() %>%
     addCircleMarkers(
         lat =  ~ latitude / 10e5,
         lng =  ~ longitude / 10e5,
         label = ~ as.character(c(bedroomcnt, bathroomcnt)),
         clusterOptions = markerClusterOptions()
     )

```






